{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"bright\")\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn  import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def ode_solve(z0, t0, t1, f):\n",
    "    \"\"\"\n",
    "    Simplest Euler ODE initial value solver\n",
    "    \"\"\"\n",
    "    h_max = 0.05\n",
    "    n_steps = math.ceil((abs(t1 - t0)/h_max).max().item())\n",
    "\n",
    "    h = (t1 - t0)/n_steps\n",
    "    t = t0\n",
    "    z = z0\n",
    "\n",
    "    for i_step in range(n_steps):\n",
    "        z = z + h * f(z, t)\n",
    "        t = t + h\n",
    "    return z\n",
    "\n",
    "class ODEF(nn.Module):\n",
    "    def forward_with_grad(self, z, t, grad_outputs):\n",
    "        \"\"\"Compute f and a df/dz, a df/dp, a df/dt\"\"\"\n",
    "        batch_size = z.shape[0]\n",
    "\n",
    "        out = self.forward(z, t)\n",
    "\n",
    "        a = grad_outputs\n",
    "        adfdz, adfdt, *adfdp = torch.autograd.grad(\n",
    "            (out,), (z, t) + tuple(self.parameters()), grad_outputs=(a),\n",
    "            allow_unused=True, retain_graph=True\n",
    "        )\n",
    "        # grad method automatically sums gradients for batch items, we have to expand them back\n",
    "        if adfdp is not None:\n",
    "            adfdp = torch.cat([p_grad.flatten() for p_grad in adfdp]).unsqueeze(0)\n",
    "            adfdp = adfdp.expand(batch_size, -1) / batch_size\n",
    "        if adfdt is not None:\n",
    "            adfdt = adfdt.expand(batch_size, 1) / batch_size\n",
    "        return out, adfdz, adfdt, adfdp\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        p_shapes = []\n",
    "        flat_parameters = []\n",
    "        for p in self.parameters():\n",
    "            p_shapes.append(p.size())\n",
    "            flat_parameters.append(p.flatten())\n",
    "        return torch.cat(flat_parameters)\n",
    "\n",
    "class ODEAdjoint(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, z0, t, flat_parameters, func):\n",
    "        assert isinstance(func, ODEF)\n",
    "        bs, *z_shape = z0.size()\n",
    "        time_len = t.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = torch.zeros(time_len, bs, *z_shape).to(z0)\n",
    "            z[0] = z0\n",
    "            for i_t in range(time_len - 1):\n",
    "                z0 = ode_solve(z0, t[i_t], t[i_t+1], func)\n",
    "                z[i_t+1] = z0\n",
    "\n",
    "        ctx.func = func\n",
    "        ctx.save_for_backward(t, z.clone(), flat_parameters)\n",
    "        return z\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dLdz):\n",
    "        \"\"\"\n",
    "        dLdz shape: time_len, batch_size, *z_shape\n",
    "        \"\"\"\n",
    "        func = ctx.func\n",
    "        t, z, flat_parameters = ctx.saved_tensors\n",
    "        time_len, bs, *z_shape = z.size()\n",
    "        n_dim = np.prod(z_shape)\n",
    "        n_params = flat_parameters.size(0)\n",
    "\n",
    "        # Dynamics of augmented system to be calculated backwards in time\n",
    "        def augmented_dynamics(aug_z_i, t_i):\n",
    "            \"\"\"\n",
    "            tensors here are temporal slices\n",
    "            t_i - is tensor with size: bs, 1\n",
    "            aug_z_i - is tensor with size: bs, n_dim*2 + n_params + 1\n",
    "            \"\"\"\n",
    "            z_i, a = aug_z_i[:, :n_dim], aug_z_i[:, n_dim:2*n_dim]  # ignore parameters and time\n",
    "\n",
    "            # Unflatten z and a\n",
    "            z_i = z_i.view(bs, *z_shape)\n",
    "            a = a.view(bs, *z_shape)\n",
    "            with torch.set_grad_enabled(True):\n",
    "                t_i = t_i.detach().requires_grad_(True)\n",
    "                z_i = z_i.detach().requires_grad_(True)\n",
    "                func_eval, adfdz, adfdt, adfdp = func.forward_with_grad(z_i, t_i, grad_outputs=a)  # bs, *z_shape\n",
    "                adfdz = adfdz.to(z_i) if adfdz is not None else torch.zeros(bs, *z_shape).to(z_i)\n",
    "                adfdp = adfdp.to(z_i) if adfdp is not None else torch.zeros(bs, n_params).to(z_i)\n",
    "                adfdt = adfdt.to(z_i) if adfdt is not None else torch.zeros(bs, 1).to(z_i)\n",
    "\n",
    "            # Flatten f and adfdz\n",
    "            func_eval = func_eval.view(bs, n_dim)\n",
    "            adfdz = adfdz.view(bs, n_dim)\n",
    "            return torch.cat((func_eval, -adfdz, -adfdp, -adfdt), dim=1)\n",
    "\n",
    "        dLdz = dLdz.view(time_len, bs, n_dim)  # flatten dLdz for convenience\n",
    "        with torch.no_grad():\n",
    "            ## Create placeholders for output gradients\n",
    "            # Prev computed backwards adjoints to be adjusted by direct gradients\n",
    "            adj_z = torch.zeros(bs, n_dim).to(dLdz)\n",
    "            adj_p = torch.zeros(bs, n_params).to(dLdz)\n",
    "            # In contrast to z and p we need to return gradients for all times\n",
    "            adj_t = torch.zeros(time_len, bs, 1).to(dLdz)\n",
    "\n",
    "            for i_t in range(time_len-1, 0, -1):\n",
    "                z_i = z[i_t]\n",
    "                t_i = t[i_t]\n",
    "                f_i = func(z_i, t_i).view(bs, n_dim)\n",
    "\n",
    "                # Compute direct gradients\n",
    "                dLdz_i = dLdz[i_t]\n",
    "                dLdt_i = torch.bmm(torch.transpose(dLdz_i.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
    "\n",
    "                # Adjusting adjoints with direct gradients\n",
    "                adj_z += dLdz_i\n",
    "                adj_t[i_t] = adj_t[i_t] - dLdt_i\n",
    "\n",
    "                # Pack augmented variable\n",
    "                aug_z = torch.cat((z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z), adj_t[i_t]), dim=-1)\n",
    "\n",
    "                # Solve augmented system backwards\n",
    "                aug_ans = ode_solve(aug_z, t_i, t[i_t-1], augmented_dynamics)\n",
    "\n",
    "                # Unpack solved backwards augmented system\n",
    "                adj_z[:] = aug_ans[:, n_dim:2*n_dim]\n",
    "                adj_p[:] += aug_ans[:, 2*n_dim:2*n_dim + n_params]\n",
    "                adj_t[i_t-1] = aug_ans[:, 2*n_dim + n_params:]\n",
    "\n",
    "                del aug_z, aug_ans\n",
    "\n",
    "            ## Adjust 0 time adjoint with direct gradients\n",
    "            # Compute direct gradients\n",
    "            dLdz_0 = dLdz[0]\n",
    "            dLdt_0 = torch.bmm(torch.transpose(dLdz_0.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
    "\n",
    "            # Adjust adjoints\n",
    "            adj_z += dLdz_0\n",
    "            adj_t[0] = adj_t[0] - dLdt_0\n",
    "        return adj_z.view(bs, *z_shape), adj_t, adj_p, None\n",
    "\n",
    "\n",
    "class NeuralODE(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super(NeuralODE, self).__init__()\n",
    "        assert isinstance(func, ODEF)\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, z0, t=Tensor([0., 1.]), return_whole_sequence=False):\n",
    "        t = t.to(z0)\n",
    "        z = ODEAdjoint.apply(z0, t, self.func.flatten_parameters(), self.func)\n",
    "        if return_whole_sequence:\n",
    "            return z\n",
    "        else:\n",
    "            return z[-1]\n",
    "\n",
    "class LinearODEF(ODEF):\n",
    "    def __init__(self, W):\n",
    "        super(LinearODEF, self).__init__()\n",
    "        self.lin = nn.Linear(5, 5, bias=False)\n",
    "        self.lin.weight = nn.Parameter(W)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.lin(x)\n",
    "\n",
    "class RandomLinearODEF(LinearODEF):\n",
    "    def __init__(self):\n",
    "        super(RandomLinearODEF, self).__init__(torch.randn(5, 5)/2.)\n",
    "\n",
    "\n",
    "def to_np(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "def conduct_experiment(obs, ode_trained, n_steps, name, plot_freq=50, epoch=5):\n",
    "    # Create data\n",
    "    z0 = Variable(torch.Tensor([[-1.0, 0, 0.1, 0.1, 0.42]]))\n",
    "\n",
    "    t_max = 6.29*5\n",
    "    n_points = 200\n",
    "\n",
    "    print(f\"Training Epoch {epoch}...\")\n",
    "\n",
    "    index_np = np.arange(0, n_points, 1, dtype=np.int)\n",
    "    index_np = np.hstack([index_np[:, None]])\n",
    "    times_np = np.linspace(0, t_max, num=n_points)\n",
    "    times_np = np.hstack([times_np[:, None]])\n",
    "\n",
    "    times = torch.from_numpy(times_np[:, :, None]).to(z0)\n",
    "    \n",
    "    # Get trajectory of random timespan\n",
    "    min_delta_time = 1.0\n",
    "    max_delta_time = 5.0\n",
    "    max_points_num = 32\n",
    "    def create_batch():\n",
    "        t0 = np.random.uniform(0, t_max - max_delta_time)\n",
    "        t1 = t0 + np.random.uniform(min_delta_time, max_delta_time)\n",
    "\n",
    "        idx = sorted(np.random.permutation(index_np[(times_np > t0) & (times_np < t1)])[:max_points_num])\n",
    "\n",
    "        obs_ = obs[idx]\n",
    "        ts_ = times[idx]\n",
    "        return obs_, ts_\n",
    "\n",
    "    # Train Neural ODE\n",
    "    optimizer = torch.optim.Adam(ode_trained.parameters(), lr=0.01)\n",
    "    train_losses = []\n",
    "    for i in range(n_steps):\n",
    "        obs_, ts_ = create_batch()\n",
    "        z_ = ode_trained(obs_[0], ts_, return_whole_sequence=True)\n",
    "        loss = F.mse_loss(z_, obs_.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    final_pars = list(ode_trained.parameters())\n",
    "    return train_losses, final_pars\n",
    "\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('sim/sim1.mat')\n",
    "\n",
    "def cal_tp_acc(mat1, mat2):\n",
    "    loc_gt = mat1 == 1\n",
    "    loc_sim = mat2 == 1\n",
    "    n_1_gt = len(mat1[loc_gt])\n",
    "    n_1_sim = len(mat2[loc_sim])\n",
    "    #cal tp,acc\n",
    "    n_corr = sum(mat1[loc_gt] == mat2[loc_gt])\n",
    "    tp = n_corr/n_1_gt\n",
    "    acc = n_corr/n_1_sim\n",
    "    return tp, acc\n",
    "\n",
    "n_epochs = 20\n",
    "result = []\n",
    "for i in range(0, 50):\n",
    "    print(f\"subject{i}\")\n",
    "    pt_down = i*200\n",
    "    pt_up = (i+1)*200-1\n",
    "    obs = mat['ts'][pt_down:pt_up]\n",
    "    obs2 = obs.reshape(obs, (200, 1, 5))\n",
    "    obs2 = torch.from_numpy(obs2)\n",
    "    gt = mat['net'][i]\n",
    "    pars_ls = []\n",
    "    ode_trained = NeuralODE(RandomLinearODEF())\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_losses, final_pars = conduct_experiment(obs2, ode_trained, 3000, i, epoch = epoch)        \n",
    "        pars = final_pars[0].detach()\n",
    "        pars_ls.append(pars)\n",
    "    par = pars_ls[-1].numpy()\n",
    "    ##evaluate performance\n",
    "    par_nom = (par - np.mean(par))/np.std(par)\n",
    "    par_bin = (abs(par_nom)>1).astype(int_)\n",
    "    gt_bin = (gt!=0).astype(int_)\n",
    "    tp, acc = cal_tp_acc(gt_bin, par_bin)\n",
    "    result.append([tp,acc])\n",
    "result_df = pd.DataFrame(result)\n",
    "result_df.columns = ['tp', 'acc']\n",
    "result_df.to_csv(\"sim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat['ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Fri Aug 24 15:45:37 2012',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'ts': array([[-1.68689769, -1.28406135, -0.6760282 , -2.56011633, -1.05423662],\n",
       "        [-0.73026723, -0.55486006, -2.55433115, -0.52633548,  1.10091925],\n",
       "        [-1.26204546, -0.78184172, -0.73325796, -0.89806382,  0.08859272],\n",
       "        ...,\n",
       "        [ 0.81775919, -0.74486774, -0.03691457,  2.57935351,  0.95366508],\n",
       "        [-2.39926171,  0.04882025, -1.39823262, -1.50496996,  2.38226749],\n",
       "        [ 2.85295637,  1.79394477,  2.63520153, -1.28656521, -1.09581382]]),\n",
       " 'net': array([[[-1.        ,  0.35674352,  0.        ,  0.        ,\n",
       "           0.28535286],\n",
       "         [ 0.        , -1.        ,  0.23344156,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.41253323,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.42876764],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]],\n",
       " \n",
       "        [[-1.        ,  0.51909155,  0.        ,  0.        ,\n",
       "           0.41746391],\n",
       "         [ 0.        , -1.        ,  0.51891642,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.39623667,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.43272924],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]],\n",
       " \n",
       "        [[-1.        ,  0.38132914,  0.        ,  0.        ,\n",
       "           0.38636041],\n",
       "         [ 0.        , -1.        ,  0.47257905,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.34116835,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.6       ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.        ,  0.28141138,  0.        ,  0.        ,\n",
       "           0.27826825],\n",
       "         [ 0.        , -1.        ,  0.29440971,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.54724799,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.40557438],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]],\n",
       " \n",
       "        [[-1.        ,  0.39587729,  0.        ,  0.        ,\n",
       "           0.49534654],\n",
       "         [ 0.        , -1.        ,  0.28716561,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.26507225,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.37388984],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]],\n",
       " \n",
       "        [[-1.        ,  0.41286444,  0.        ,  0.        ,\n",
       "           0.373756  ],\n",
       "         [ 0.        , -1.        ,  0.46564675,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.28321806,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.35393948],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]]]),\n",
       " 'Nnodes': array([[5]], dtype=uint8),\n",
       " 'Nsubjects': array([[50]], dtype=uint8),\n",
       " 'Ntimepoints': array([[200]], dtype=uint8)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('sim/sim1.mat')\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ,  0.38132914,  0.        ,  0.        ,  0.38636041],\n",
       "       [ 0.        , -1.        ,  0.47257905,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -1.        ,  0.34116835,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , -1.        ,  0.6       ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        , -1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['net'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['Ntimepoints'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 6 9 19 20 25, 26, 27 not 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim1 has 200 points\n",
      "sim2 has 200 points\n",
      "sim3 has 200 points\n",
      "sim4 has 200 points\n",
      "sim5 has 1200 points\n",
      "sim6 has 1200 points\n",
      "sim7 has 5000 points\n",
      "sim8 has 200 points\n",
      "sim9 has 5000 points\n",
      "sim10 has 200 points\n",
      "sim11 has 200 points\n",
      "sim12 has 200 points\n",
      "sim13 has 200 points\n",
      "sim14 has 200 points\n",
      "sim15 has 200 points\n",
      "sim16 has 200 points\n",
      "sim17 has 200 points\n",
      "sim18 has 200 points\n",
      "sim19 has 2400 points\n",
      "sim20 has 2400 points\n",
      "sim21 has 200 points\n",
      "sim22 has 200 points\n",
      "sim23 has 200 points\n",
      "sim24 has 200 points\n",
      "sim25 has 100 points\n",
      "sim26 has 50 points\n",
      "sim27 has 50 points\n",
      "sim28 has 100 points\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "for i in range(1,29):\n",
    "    mat = scipy.io.loadmat(f'sim/sim{i}.mat')\n",
    "    print(f\"sim{i} has {mat['Ntimepoints'][0][0]} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = mat['ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['ts'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=12\n",
    "pt_down = i*50\n",
    "pt_up = (i+1)*200\n",
    "obs = mat['ts'][pt_down:pt_up]\n",
    "obs = obs.astype('float32')\n",
    "#obs2 = np.reshape(obs, (200, 1, 5))\n",
    "#obs2 = torch.from_numpy(obs2)\n",
    "#gt = mat['net'][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Fri Aug 24 15:45:50 2012',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'ts': array([[-0.09369639,  0.30913995,  0.9171731 , -0.96691504,  0.53896468],\n",
       "        [ 0.40971644,  0.58512361, -1.41434747,  0.6136482 ,  2.24090292],\n",
       "        [ 0.20502844,  0.68523219,  0.73381594,  0.56901009,  1.55566662],\n",
       "        ...,\n",
       "        [-0.46984943, -2.03247636, -1.32452319,  1.29174489, -0.33394354],\n",
       "        [-4.31158452, -1.86350256, -3.31055543, -3.41729277,  0.46994468],\n",
       "        [ 1.68266271,  0.62365111,  1.46490787, -2.45685887, -2.26610748]]),\n",
       " 'net': array([[[-1.        ,  0.35674352,  0.        ,  0.        ,\n",
       "           0.28535286],\n",
       "         [ 0.        , -1.        ,  0.23344156,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.41253323,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.42876764],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]],\n",
       " \n",
       "        [[-1.        ,  0.51909155,  0.        ,  0.        ,\n",
       "           0.41746391],\n",
       "         [ 0.        , -1.        ,  0.51891642,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.39623667,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.43272924],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]],\n",
       " \n",
       "        [[-1.        ,  0.38132914,  0.        ,  0.        ,\n",
       "           0.38636041],\n",
       "         [ 0.        , -1.        ,  0.47257905,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.34116835,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.6       ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.        ,  0.28141138,  0.        ,  0.        ,\n",
       "           0.27826825],\n",
       "         [ 0.        , -1.        ,  0.29440971,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.54724799,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.40557438],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]],\n",
       " \n",
       "        [[-1.        ,  0.39587729,  0.        ,  0.        ,\n",
       "           0.49534654],\n",
       "         [ 0.        , -1.        ,  0.28716561,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.26507225,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.37388984],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]],\n",
       " \n",
       "        [[-1.        ,  0.41286444,  0.        ,  0.        ,\n",
       "           0.373756  ],\n",
       "         [ 0.        , -1.        ,  0.46564675,  0.        ,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        , -1.        ,  0.28321806,\n",
       "           0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -1.        ,\n",
       "           0.35393948],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -1.        ]]]),\n",
       " 'Nnodes': array([[5]], dtype=uint8),\n",
       " 'Nsubjects': array([[50]], dtype=uint8),\n",
       " 'Ntimepoints': array([[200]], dtype=uint8)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ,  0.38132914,  0.        ,  0.        ,  0.38636041],\n",
       "       [ 0.        , -1.        ,  0.47257905,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -1.        ,  0.34116835,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , -1.        ,  0.6       ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        , -1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['net'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7758e92e9a61d7a3490898707f7eeb937c85e9d1e8d4e877cc6c187218f226d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
